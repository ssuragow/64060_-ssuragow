---
title: "Assignment 3"
author: "Swathi Suragowni Ravindranath"
date: '2022-03-06'
output: pdf_document
---

```{r setup}

BankData <- read.csv("C:/Users/ravin/Downloads/UniversalBank.csv")
summary(BankData)
library(caret)
library(ISLR)
library(e1071)
library(dplyr)
library(class)
library(reshape2)
library(ggplot2)
library(gmodels)
library(lattice)

#converting variables
BankData$Personal.Loan <- factor(BankData$Personal.Loan)
BankData$Online <- factor(BankData$Online)
BankData$CreditCard <- factor(BankData$CreditCard)
df= BankData

#TASK1
set.seed(64060)
Train_index <- createDataPartition(df$Personal.Loan, p = 0.6, list = FALSE)
train.df = df[Train_index,]
validation.df = df[-Train_index,]

mytable <- xtabs(~ CreditCard + Online + Personal.Loan , data = train.df)
ftable(mytable)


#TASK2

probability = 59/(59+479)
probability


#Q3

table(Personal.Loan = train.df$Personal.Loan, Online = train.df$Online)

table(Personal.Loan = train.df$Personal.Loan, CreditCard = train.df$CreditCard)
table(Personal.Loan = train.df$Personal.Loan)

#TASK4

#i. P(CC = 1 | Loan = 1) (the proportion of credit card holders among the loan 
#acceptors) 
Probablity1 <- 93/(93+195)
Probablity1

#ii. P(Online = 1 | Loan = 1)  
Probablity2 <- 179/(179+109)
Probablity2

#iii. P(Loan = 1) (the proportion of loan acceptors)  
Probablity3 <- 288/(288+2712)
Probablity3
#iv. P(CC = 1 | Loan = 0)  
Probablity4 <- 788/(788+1924)
Probablity4

#v. P(Online = 1 | Loan = 0) 
Probablity5 <- 1631/(1631+1081)
Probablity5

#vi. P(Loan = 0) 
Probablity6 <- 2712/(2712+288)
Probablity6

#Q5

Task5Probablity <- (Probablity1*Probablity2*Probablity3)/
((Probablity1*Probablity2*Probablity3) +(Probablity4*Probablity5*Probablity6))
                                                                    
Task5Probablity 

#TASK6


##Value we got from question 2 and in the question 5 are nearly same 
#Difference #between  exact method and naive bayes method is the exact method
#We need the similar independent variable and classification to pridict, whereas the naive bayes
#method doesn't. We can justify  that value we got from the question 2 i.e 0.1096654 more precise.
#because we have taken the same values from the pivot table.




#Task7

#Run naive Bayes on the data. Examine the model output on training data, and find the entry
#that corresponds to P(Loan = 1 | CC = 1, Online = 1). Compare this to the number you
#obtained in (E).

nb.model <- naiveBayes(Personal.Loan~ Online + CreditCard, data = train.df)
To_Predict=data.frame(Online=1, CreditCard= 1)
predict(nb.model, To_Predict,type = 'raw')

#The value we got from question 7  is 0.08463445 and value derived from the task 5 is 0.1087106.
# the result is almost same that we got from Task5.
# There is min difference because of the rounding off.
#The difference will not effect the rank .


```

